{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58a4138c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code 1\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import datasets, layers, models\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from keras.models import Sequential\n",
    "from keras.utils import to_categorical\n",
    "from keras.layers import MaxPooling2D, Conv2D, Flatten, Dense, Dropout, Activation\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#load data\n",
    "(x_train, y_train), (x_test, y_test) = cifar100.load_data()\n",
    "\n",
    "#checking data and array shape \n",
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)\n",
    "\n",
    "#Splitting training data into training and validation\n",
    "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=42)\n",
    "\n",
    "#https://www.geeksforgeeks.org/image-classification-using-cifar-10-and-cifar-100-dataset-in-tensorflow/\n",
    "def show_samples(data, labels):\n",
    "    plt.subplots(figsize=(10, 10))\n",
    "    for i in range(12):\n",
    "        plt.subplot(3, 4, i+1)\n",
    "        k = np.random.randint(0, data.shape[0])\n",
    "        plt.title(int(labels[k]))\n",
    "        plt.imshow(data[k])\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "show_samples(x_train, y_train)\n",
    "\n",
    "\n",
    "#Processing data \n",
    "#Converting pixels to float type\n",
    "#https://github.com/LeoTungAnh/CNN-CIFAR-100/blob/main/CNN_models.ipynb\n",
    "x_train = x_train.astype('float32') / 255.\n",
    "x_val = x_val.astype('float32') / 255.\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "#One hot encoding to target classes \n",
    "classes = 100\n",
    "ytrain_categories = to_categorical(y_train, num_classes=100)\n",
    "yval_categories = to_categorical(y_val, num_classes=100)\n",
    "ytest_categories = to_categorical(y_test, num_classes=100)\n",
    "\n",
    "#Building CNN model \n",
    "#Uses layers as a 'filtering' system that making model learn based on patterns from training\n",
    "#https://github.com/uzairlol/CIFAR100-Image-Classification-CNN/blob/main/Item%20Image%20Model%20Training%20and%20Evaluation.ipynb\n",
    "model = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2, 2)),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "    keras.layers.MaxPooling2D((2,2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='relu'),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(100, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "\n",
    "#Beginning the training of model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "#main training section\n",
    "#chatgpt helped to structure how model can undergo training\n",
    "history = model.fit(x_train, ytrain_categories, epochs=25, batch_size=64, validation_data=(x_val, yval_categories))\n",
    "\n",
    "test_loss, test_accuracy = model.evaluate(x_test, ytest_categories)\n",
    "print(f\"Test accuracy: {test_accuracy * 100:.2f}%\")\n",
    "\n",
    "#visualisation of results through graphs using matplotlib\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.title('Accuracy over Epochs')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Loss over Epochs')\n",
    "plt.xlabel('Epoch Number')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "# Note: IF ERROR OCCURS TRY:\n",
    "# REFRESHING KERNEL \n",
    "# UPDATING LIBRARIES AND MODULES (LIKE NUMPY AND TENSORFLOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0afe4580",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import cifar100\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import os\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "\n",
    "from tensorflow.keras.mixed_precision import Policy\n",
    "policy = Policy('mixed_float16')\n",
    "tf.keras.mixed_precision.set_global_policy(policy)\n",
    "\n",
    "# This is to load the data from the tensorflow dataset cifar 100\n",
    "(X_train, y_train), (X_test, y_test) = cifar100.load_data()\n",
    "num_classes = len(np.unique(y_train))\n",
    "print(X_train.shape, X_test.shape)\n",
    "\n",
    "#check one image to see what it looks like and randomly \n",
    "# we picked index 12 to test.\n",
    "imageindex = 12\n",
    "print(f\"array pointer = {imageindex}\")\n",
    "print(f\"image shape: {X_train[imageindex].shape}\")\n",
    "print(f\"Class label: {y_train[imageindex][0]}\") # [0] since it is a 2D array\n",
    "\n",
    "#this prints the image and shows it on a graph\n",
    "plt.imshow(X_train[imageindex],cmap='viridis')\n",
    "plt.show()\n",
    "\n",
    "def check_pics(data, dataset_name):\n",
    "    \"\"\"\n",
    "    Check CIFAR-100 images for:\n",
    "    - Array type\n",
    "    - Shape (32x32x3)\n",
    "    - Pixel values (0-255)\n",
    "    - No NaNs\n",
    "    \"\"\"\n",
    "    bad_imgs = 0\n",
    "    good_imgs = 0\n",
    "    for i, img in enumerate(data):\n",
    "        if not isinstance(img, np.ndarray):\n",
    "            print(f\"{dataset_name} img {i}: Not an array\")\n",
    "            bad_imgs += 1\n",
    "            continue\n",
    "        if img.shape != (32, 32, 3):\n",
    "            print(f\"{dataset_name} img {i}: Shape {img.shape}, need (32, 32, 3)\")\n",
    "            bad_imgs += 1\n",
    "            continue\n",
    "        if not (img.dtype == np.uint8 and img.min() >= 0 and img.max() <= 255):\n",
    "            print(f\"{dataset_name} img {i}: Bad pixels, min={img.min()}, max={img.max()}\")\n",
    "            bad_imgs += 1\n",
    "            continue\n",
    "        if np.isnan(img).any():\n",
    "            print(f\"{dataset_name} img {i}: NaN found\")\n",
    "            bad_imgs += 1\n",
    "            continue\n",
    "        good_imgs += 1\n",
    "    print(f\"{dataset_name}: {good_imgs} good, {bad_imgs} bad\")\n",
    "\n",
    "print(\"Checking images...\\n\")\n",
    "check_pics(X_train, \"Train\")\n",
    "check_pics(X_test, \"Test\")\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    test_size=0.2,\n",
    "    random_state=15\n",
    ")\n",
    "\n",
    "#checking to see if the shapes are the same \n",
    "print(\"Training set:\", X_train.shape, y_train.shape)\n",
    "print(\"Validating set:\", X_val.shape, y_val.shape)\n",
    "print(\"Test set:\", X_test.shape, y_test.shape)\n",
    "\n",
    "# Normalising pixels to 0-1\n",
    "X_train = X_train.astype('float32') / 255\n",
    "X_val = X_val.astype('float32') / 255\n",
    "X_test = X_test.astype('float32') / 255\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train = to_categorical(y_train, num_classes)\n",
    "y_val = to_categorical(y_val, num_classes)\n",
    "y_test = to_categorical(y_test, num_classes)\n",
    "\n",
    "counts = pd.DataFrame(columns=['Set', 'Class', 'Count'])\n",
    "def count_cls(data, name):\n",
    "    global counts\n",
    "    cls, nums = np.unique(np.argmax(data, axis=1) if data.ndim > 1 else data, return_counts=True)\n",
    "    for c, n in zip(cls, nums):\n",
    "        counts = pd.concat([counts, pd.DataFrame([{'Set': name, 'Class': str(c), 'Count': n}])], ignore_index=True)\n",
    "\n",
    "count_cls(y_train, \"Train\")\n",
    "count_cls(y_val, \"Val\")\n",
    "count_cls(y_test, \"Test\")\n",
    "\n",
    "# Plot class counts\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.barplot(data=counts, x='Set', y='Count', hue='Class')\n",
    "plt.title(\"Class Counts\")\n",
    "plt.legend([], [], frameon=False)  # Too many classes\n",
    "\n",
    "# Model 1: Very Lightweight CNN\n",
    "# Super simple to train fast\n",
    "def light_cnn(shape, classes):\n",
    "    model = Sequential()\n",
    "    model.add(Conv2D(16, (3, 3), activation='relu', input_shape=shape, padding='same'))\n",
    "    model.add(MaxPool2D((2, 2)))\n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', padding='same'))\n",
    "    model.add(MaxPool2D((2, 2)))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(classes, activation='softmax'))\n",
    "    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "cnn1 = light_cnn((32, 32, 3), num_classes)\n",
    "cnn1.summary()\n",
    "\n",
    "# Train with bigger batch size\n",
    "stop = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)\n",
    "\n",
    "# Use tf.data for faster loading\n",
    "train_data = tf.data.Dataset.from_tensor_slices((X_train, y_train)).shuffle(10000).batch(128).prefetch(tf.data.AUTOTUNE)\n",
    "val_data = tf.data.Dataset.from_tensor_slices((X_val, y_val)).batch(128).prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "print(\"Training Light CNN...\")\n",
    "cnn1_hist = cnn1.fit(\n",
    "    train_data,\n",
    "    epochs=20,  # Less epochs to be quick\n",
    "    validation_data=val_data,\n",
    "    callbacks=[stop]\n",
    ")\n",
    "\n",
    "# Plot training\n",
    "def plot_training(hist, name):\n",
    "    df = pd.DataFrame(hist.history)\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(df['loss'], label='Train')\n",
    "    plt.plot(df['val_loss'], label='Val')\n",
    "    plt.title(f'{name} Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(df['accuracy'], label='Train')\n",
    "    plt.plot(df['val_accuracy'], label='Val')\n",
    "    plt.title(f'{name} Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "\n",
    "plot_training(cnn1_hist, \"light_cnn\")\n",
    "\n",
    "# Test models\n",
    "cnn1_loss, cnn1_acc = cnn1.evaluate(X_test, y_test)\n",
    "print(f\"Light CNN: Loss = {cnn1_loss:.4f}, Acc = {cnn1_acc:.4f}\")\n",
    "\n",
    "# Predict\n",
    "idx = 100\n",
    "img = X_test[idx:idx+1]\n",
    "true = np.argmax(y_test[idx])\n",
    "probs = cnn1.predict(img)\n",
    "pred = np.argmax(probs)\n",
    "\n",
    "plt.figure(figsize=(3, 3))\n",
    "plt.imshow(img[0])\n",
    "plt.title(f\"True: {class_names[true]}, Pred: {class_names[pred]}\")\n",
    "plt.axis('off')\n",
    "\n",
    "# Probabilities (top 10)\n",
    "prob_df = pd.DataFrame(probs[0], columns=['Prob'])\n",
    "prob_df['Class'] = class_names\n",
    "plt.figure(figsize=(12, 4))\n",
    "sns.barplot(data=prob_df.head(10), x='Class', y='Prob')\n",
    "plt.title('Top Probabilities')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Results\n",
    "def show_results(data, labels, model):\n",
    "    preds = np.argmax(model.predict(data), axis=1)\n",
    "    true = np.argmax(labels, axis=1)\n",
    "    \n",
    "    # Compute confusion matrix\n",
    "    cm = confusion_matrix(true, preds)\n",
    "    \n",
    "    # Plot confusion matrix\n",
    "    plt.figure(figsize=(20, 20))  # Big plot for 100 classes\n",
    "    sns.heatmap(cm, annot=False, fmt='d', cmap='Blues', xticklabels=class_names, yticklabels=class_names)\n",
    "    plt.title('Confusion Matrix')\n",
    "    plt.xlabel('Predicted')\n",
    "    plt.ylabel('True')\n",
    "    plt.xticks(rotation=90, fontsize=8)\n",
    "    plt.yticks(rotation=0, fontsize=8)\n",
    "    \n",
    "    # Print confusion matrix\n",
    "    print(\"Confusion Matrix (rows/cols are class names):\")\n",
    "    cm_df = pd.DataFrame(cm, index=class_names, columns=class_names)\n",
    "    print(cm_df)\n",
    "    \n",
    "    # Classification report\n",
    "    print(\"\\nClassification Report:\")\n",
    "    print(classification_report(true, preds, target_names=class_names))\n",
    "\n",
    "show_results(X_test, y_test, cnn1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
